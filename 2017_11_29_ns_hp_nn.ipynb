{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T23:25:00.120696Z",
     "start_time": "2020-04-28T23:24:58.710145Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoX could not be found!\n",
      "\n",
      "    If you do not have SoX, proceed here:\n",
      "     - - - http://sox.sourceforge.net/ - - -\n",
      "\n",
      "    If you do (or think that you should) have SoX, double-check your\n",
      "    path variables.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import audtorch.metrics.functional as audtorch\n",
    "\n",
    "import time\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T06:30:39.044431Z",
     "start_time": "2020-04-19T06:30:39.036348Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class FullNonLinear(nn.Module):\n",
    "    def __init__(self, unit_no, t_dim, h_dim, p_dim):\n",
    "        super(FullNonLinear, self).__init__()\n",
    "        self.unit_no = unit_no\n",
    "        self.t_dim = t_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.p_dim = p_dim\n",
    "        \n",
    "        self.input_layer = nn.Sequential(\n",
    "                            nn.Linear(self.unit_no * self.t_dim , self.h_dim),\n",
    "                            nn.Tanh()).cuda()\n",
    "        self.hidden1 = nn.Sequential(\n",
    "                            nn.Linear(self.h_dim, self.h_dim),\n",
    "                            nn.Tanh()).cuda()\n",
    "        self.hidden2 = nn.Sequential(\n",
    "                            nn.Linear(self.h_dim, self.h_dim),\n",
    "                            nn.Tanh()).cuda()\n",
    "        self.hidden3 = nn.Sequential(\n",
    "                            nn.Linear(self.h_dim, self.h_dim),\n",
    "                            nn.Tanh()).cuda()\n",
    "        self.output_layer = nn.Linear(self.h_dim, self.p_dim).cuda()\n",
    "        \n",
    "    def forward(self, S):\n",
    "        \n",
    "        out = self.input_layer(S)\n",
    "        out = self.hidden1(out)\n",
    "        out = self.hidden2(out)\n",
    "        out = self.hidden3(out)\n",
    "        out = self.output_layer(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T23:25:00.133882Z",
     "start_time": "2020-04-28T23:25:00.122394Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class PartNonLinear(nn.Module):\n",
    "    def __init__(self, unit_no, t_dim, k_dim, h_dim, p_dim, f_dim):\n",
    "        super(PartNonLinear, self).__init__()\n",
    "        self.unit_no = unit_no\n",
    "        self.t_dim = t_dim\n",
    "        self.h_dim = h_dim\n",
    "        self.p_dim = p_dim\n",
    "        self.k_dim = k_dim\n",
    "        self.f_dim = f_dim\n",
    "        \n",
    "        self.featurize = nn.ModuleList([nn.Linear(self.t_dim,\n",
    "                                                  self.f_dim) for i in range(self.unit_no)]).cuda()\n",
    "        \n",
    "        self.hidden1 = nn.ModuleList([nn.Linear(self.k_dim*self.f_dim,\n",
    "                                               self.h_dim) for i in range(self.p_dim)]).cuda()\n",
    "        self.hidden1_act = nn.ModuleList([nn.PReLU() for i in range(self.p_dim)]).cuda()\n",
    "        \n",
    "        self.output_layer = nn.ModuleList([nn.Linear(self.h_dim,\n",
    "                                                    1) for i in range(self.p_dim)]).cuda()\n",
    "        \n",
    "    def forward(self, S, pix_units):\n",
    "        \n",
    "        F = torch.empty(S.shape[0], self.unit_no * self.f_dim).cuda()\n",
    "        for n in range(self.unit_no):\n",
    "            feat_n = self.featurize[n](S[:, n*self.t_dim : (n+1)*self.t_dim])\n",
    "            F[:, n*self.f_dim : (n+1)*self.f_dim] = feat_n\n",
    "        \n",
    "        I = torch.empty(S.shape[0] , self.p_dim).cuda()\n",
    "        \n",
    "        for x in range(self.p_dim):\n",
    "            unit_ids = pix_units[x]\n",
    "            feat_ids = torch.empty((self.k_dim * self.f_dim))\n",
    "            for i in range(self.k_dim):\n",
    "                feat_ids[i*self.f_dim : (i+1)*self.f_dim] = torch.arange(self.f_dim) + unit_ids[i]*self.f_dim\n",
    "            \n",
    "            pix_feat = self.hidden1[x](F[:, feat_ids.long()])\n",
    "            pix_feat = self.hidden1_act[x](pix_feat)\n",
    "\n",
    "            out = self.output_layer[x](pix_feat)\n",
    "            \n",
    "            I[:, x] = out.reshape(-1)\n",
    "            \n",
    "        return I            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T23:25:02.561591Z",
     "start_time": "2020-04-28T23:25:00.208876Z"
    }
   },
   "outputs": [],
   "source": [
    "t_dim = 50\n",
    "k_dim = 10\n",
    "h_dim = 40\n",
    "f_dim = 10\n",
    "\n",
    "unit_no = 2094\n",
    "image_no = 9800\n",
    "#image_no = 2000\n",
    "p_dim = 95*146\n",
    "#p_dim = 730\n",
    "\n",
    "epoch_no = 16\n",
    "batch_size = 64\n",
    "batch_no = epoch_no * image_no // batch_size\n",
    "\n",
    "batch_ids = np.tile(np.arange(image_no).reshape((1,-1)), (epoch_no, 1))\n",
    "for i in range(epoch_no):\n",
    "    np.random.shuffle(batch_ids[i])\n",
    "batch_ids = batch_ids.reshape((batch_no, batch_size))\n",
    "batch_ids = torch.from_numpy(batch_ids).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T23:25:05.275246Z",
     "start_time": "2020-04-28T23:25:02.564111Z"
    }
   },
   "outputs": [],
   "source": [
    "S = np.load(\"/ssd/joon/2017_11_29_ns/yass/neural/yass_lin_50_train_neural.npy\")\n",
    "#S = np.load(\"/ssd/joon/2017_11_29_ns/yass/neural/yass_i2000_50_train_neural.npy\")\n",
    "S = torch.from_numpy(S)\n",
    "\n",
    "I = np.load(\"/ssd/joon/2017_11_29_ns/images/smooth_train_images.npy\")\n",
    "#I = np.load(\"/ssd/joon/2017_11_29_ns/images/i2000_p730_hp_train_images.npy\")\n",
    "I = torch.from_numpy(I)\n",
    "\n",
    "pixel_units = np.load(\"/ssd/joon/2017_11_29_ns/yass/yass_l1_pixel_units.npy\")[:,:k_dim]\n",
    "pixel_units = torch.from_numpy(pixel_units).cuda()\n",
    "\n",
    "test_S = np.load(\"/ssd/joon/2017_11_29_ns/yass/neural/yass_lin_50_test_neural.npy\")\n",
    "test_S = torch.from_numpy(test_S)\n",
    "\n",
    "test_I = np.load(\"/ssd/joon/2017_11_29_ns/images/smooth_test_images.npy\")\n",
    "test_I = torch.from_numpy(test_I).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T23:25:17.485208Z",
     "start_time": "2020-04-28T23:25:05.277211Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PartNonLinear(unit_no, t_dim, k_dim, h_dim, p_dim, f_dim)\n",
    "model = model.float()\n",
    "model.cuda()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=5.0e-6)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5.0e-6)\n",
    "\n",
    "#milestones = [batch_no//4, batch_no//2, batch_no*3//4, batch_no*7//8]\n",
    "#print(milestones)\n",
    "#lr_decay = 0.6\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-28T23:25:00.633Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e7f34b6f3741e99e8a7c95dbdcf1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2450), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 Batch_Corr: -0.0028036960501038456 , Time: 38.523348569869995\n",
      "Iter 1 Batch_Corr: -0.003907877821444815 , Time: 37.92855882644653\n",
      "Iter 2 Batch_Corr: -0.004114058391939924 , Time: 39.94805574417114\n",
      "Iter 3 Batch_Corr: -0.0032817184931996377 , Time: 38.26425838470459\n",
      "Iter 4 Batch_Corr: -0.005554183451873845 , Time: 39.878594398498535\n",
      "Iter 5 Batch_Corr: -0.002499122022147872 , Time: 39.57295823097229\n",
      "Iter 6 Batch_Corr: -0.0032812531503774145 , Time: 39.933507442474365\n",
      "Iter 7 Batch_Corr: -0.0028352754474645922 , Time: 40.24218964576721\n",
      "Iter 8 Batch_Corr: -0.0033364332799539803 , Time: 40.56747055053711\n",
      "Iter 9 Batch_Corr: -0.0014747615344647448 , Time: 38.6614043712616\n",
      "Iter 10 Batch_Corr: -0.0017777980974500996 , Time: 40.68708515167236\n",
      "Iter 11 Batch_Corr: -0.002602323429681393 , Time: 39.462889194488525\n",
      "Iter 12 Batch_Corr: -0.00402081087921542 , Time: 40.382874965667725\n",
      "Iter 13 Batch_Corr: -0.0009213680007150545 , Time: 38.764851808547974\n",
      "Iter 14 Batch_Corr: -0.00046821303339890125 , Time: 39.23659586906433\n",
      "Iter 15 Batch_Corr: 0.0021116633734451283 , Time: 39.38906002044678\n",
      "Iter 16 Batch_Corr: 0.0017196765776215442 , Time: 38.79003620147705\n",
      "Iter 17 Batch_Corr: 0.004156989402562953 , Time: 39.69496154785156\n",
      "Iter 18 Batch_Corr: 0.0033549921049277364 , Time: 39.36679148674011\n",
      "Iter 19 Batch_Corr: 0.0023607245024914784 , Time: 39.90457057952881\n",
      "Iter 20 Batch_Corr: 0.0032705472431357333 , Time: 39.33960700035095\n",
      "Iter 21 Batch_Corr: 0.003692132614288853 , Time: 40.35207509994507\n",
      "Iter 22 Batch_Corr: 0.0034034569593237546 , Time: 40.30140733718872\n",
      "Iter 23 Batch_Corr: 0.006462100644492596 , Time: 40.38014459609985\n",
      "Iter 24 Batch_Corr: 0.005041550482735721 , Time: 39.2788348197937\n",
      "Iter 25 Batch_Corr: 0.008731703713554754 , Time: 40.48000526428223\n",
      "Iter 26 Batch_Corr: 0.009961353445946538 , Time: 39.498597621917725\n",
      "Iter 27 Batch_Corr: 0.011166152385570071 , Time: 39.97029519081116\n",
      "Iter 28 Batch_Corr: 0.012568857442357273 , Time: 39.7845733165741\n",
      "Iter 29 Batch_Corr: 0.01521518856965194 , Time: 40.334259271621704\n",
      "Iter 30 Batch_Corr: 0.009672258396423945 , Time: 39.858633041381836\n",
      "Iter 31 Batch_Corr: 0.012893088958529725 , Time: 40.8026168346405\n",
      "Iter 32 Batch_Corr: 0.02533173249094194 , Time: 39.69151473045349\n",
      "Iter 33 Batch_Corr: 0.02181125468830798 , Time: 39.53309679031372\n",
      "Iter 34 Batch_Corr: 0.024945253907501536 , Time: 39.8487343788147\n",
      "Iter 35 Batch_Corr: 0.024910136359765227 , Time: 39.183852195739746\n",
      "Iter 36 Batch_Corr: 0.030421885684263978 , Time: 39.436582803726196\n",
      "Iter 37 Batch_Corr: 0.0211135779605791 , Time: 39.80133819580078\n",
      "Iter 38 Batch_Corr: 0.03480393018676756 , Time: 40.134636640548706\n",
      "Iter 39 Batch_Corr: 0.03063671472565641 , Time: 40.026588439941406\n",
      "Iter 40 Batch_Corr: 0.04167752561264459 , Time: 40.36025047302246\n",
      "Iter 41 Batch_Corr: 0.047173639513334996 , Time: 39.63183355331421\n",
      "Iter 42 Batch_Corr: 0.036198196818141015 , Time: 40.64649510383606\n",
      "Iter 43 Batch_Corr: 0.05449704236037662 , Time: 40.24401521682739\n",
      "Iter 44 Batch_Corr: 0.06423290246875994 , Time: 39.91853141784668\n",
      "Iter 45 Batch_Corr: 0.05980414396051522 , Time: 39.6871542930603\n",
      "Iter 46 Batch_Corr: 0.03648529419950465 , Time: 39.602789878845215\n",
      "Iter 47 Batch_Corr: 0.07305351489878106 , Time: 40.41694712638855\n",
      "Iter 48 Batch_Corr: 0.06391439308775385 , Time: 41.05353903770447\n",
      "Test 49: 0.08556409064802918\n",
      "Iter 49 Batch_Corr: 0.08067343983376729 , Time: 40.07719659805298\n",
      "Iter 50 Batch_Corr: 0.08932816773928903 , Time: 40.76407241821289\n",
      "Iter 51 Batch_Corr: 0.09505788450958212 , Time: 39.61048364639282\n",
      "Iter 52 Batch_Corr: 0.08488838881155022 , Time: 40.28059482574463\n",
      "Iter 53 Batch_Corr: 0.11540823740249999 , Time: 39.2917959690094\n",
      "Iter 54 Batch_Corr: 0.11126285454750304 , Time: 40.368839263916016\n",
      "Iter 55 Batch_Corr: 0.12027855670821955 , Time: 40.275704860687256\n",
      "Iter 56 Batch_Corr: 0.09948852916488832 , Time: 40.89000749588013\n",
      "Iter 57 Batch_Corr: 0.11584119535350047 , Time: 40.17747616767883\n",
      "Iter 58 Batch_Corr: 0.12302988064003349 , Time: 40.42267632484436\n",
      "Iter 59 Batch_Corr: 0.12280619477164507 , Time: 39.608635663986206\n",
      "Iter 60 Batch_Corr: 0.13525223447128829 , Time: 39.95774054527283\n",
      "Iter 61 Batch_Corr: 0.17618686343744216 , Time: 39.35620999336243\n",
      "Iter 62 Batch_Corr: 0.1939559881151843 , Time: 39.94819116592407\n",
      "Iter 63 Batch_Corr: 0.17142566030183742 , Time: 39.72207808494568\n",
      "Iter 64 Batch_Corr: 0.1588356340186419 , Time: 40.196988582611084\n",
      "Iter 65 Batch_Corr: 0.16908779109686325 , Time: 39.38208198547363\n",
      "Iter 66 Batch_Corr: 0.2129673503900556 , Time: 41.2576265335083\n",
      "Iter 67 Batch_Corr: 0.15244027873613405 , Time: 40.16005802154541\n",
      "Iter 68 Batch_Corr: 0.20341796770360573 , Time: 39.94820976257324\n",
      "Iter 69 Batch_Corr: 0.24264263009341006 , Time: 40.357463121414185\n",
      "Iter 70 Batch_Corr: 0.1934009191701894 , Time: 39.120888233184814\n",
      "Iter 71 Batch_Corr: 0.28800346070951516 , Time: 39.61590766906738\n",
      "Iter 72 Batch_Corr: 0.15658910121201908 , Time: 40.88777470588684\n",
      "Iter 73 Batch_Corr: 0.24810956197637288 , Time: 40.287299156188965\n",
      "Iter 74 Batch_Corr: 0.3270924471006873 , Time: 39.65629816055298\n",
      "Iter 75 Batch_Corr: 0.29651551542622256 , Time: 41.12237548828125\n",
      "Iter 76 Batch_Corr: 0.23028013510988551 , Time: 40.23779106140137\n",
      "Iter 77 Batch_Corr: 0.2850114665095131 , Time: 39.850989818573\n",
      "Iter 78 Batch_Corr: 0.28019528409585287 , Time: 40.0479302406311\n",
      "Iter 79 Batch_Corr: 0.34626969504954824 , Time: 39.77384161949158\n",
      "Iter 80 Batch_Corr: 0.240044520157042 , Time: 40.00454783439636\n",
      "Iter 81 Batch_Corr: 0.31342298921301176 , Time: 40.885703325271606\n",
      "Iter 82 Batch_Corr: 0.17195489794146865 , Time: 40.49668622016907\n",
      "Iter 83 Batch_Corr: 0.24375679072922798 , Time: 39.16166305541992\n",
      "Iter 84 Batch_Corr: 0.35771874504651247 , Time: 40.63500142097473\n",
      "Iter 85 Batch_Corr: 0.27548842342508767 , Time: 39.218658685684204\n",
      "Iter 86 Batch_Corr: 0.274622383166368 , Time: 40.155022382736206\n",
      "Iter 87 Batch_Corr: 0.3480242217966742 , Time: 39.77190399169922\n",
      "Iter 88 Batch_Corr: 0.25871795316774404 , Time: 40.679718017578125\n",
      "Iter 89 Batch_Corr: 0.2509465045145241 , Time: 33.09068202972412\n",
      "Iter 90 Batch_Corr: 0.3401818466828712 , Time: 28.26601481437683\n",
      "Iter 91 Batch_Corr: 0.2940484990158645 , Time: 26.98370671272278\n",
      "Iter 92 Batch_Corr: 0.2576134875791997 , Time: 28.982296228408813\n",
      "Iter 93 Batch_Corr: 0.32904880921756613 , Time: 28.933600187301636\n",
      "Iter 94 Batch_Corr: 0.3283468745497213 , Time: 29.820186376571655\n",
      "Iter 95 Batch_Corr: 0.2510983862688641 , Time: 27.558937311172485\n",
      "Iter 96 Batch_Corr: 0.20892988950966257 , Time: 29.1204993724823\n",
      "Iter 97 Batch_Corr: 0.24588817235515353 , Time: 28.830519437789917\n",
      "Iter 98 Batch_Corr: 0.3124944146545219 , Time: 27.41722297668457\n",
      "Test 99: 0.30965615479130787\n",
      "Iter 99 Batch_Corr: 0.21754680295305928 , Time: 28.531900882720947\n",
      "Iter 100 Batch_Corr: 0.30055144133296996 , Time: 29.182915449142456\n",
      "Iter 101 Batch_Corr: 0.2875269251926248 , Time: 27.41329789161682\n",
      "Iter 102 Batch_Corr: 0.29039834116127733 , Time: 28.685285568237305\n",
      "Iter 103 Batch_Corr: 0.336233122597101 , Time: 28.3076593875885\n",
      "Iter 104 Batch_Corr: 0.222028492721182 , Time: 27.93394923210144\n",
      "Iter 105 Batch_Corr: 0.26611810621459786 , Time: 28.93626070022583\n",
      "Iter 106 Batch_Corr: 0.2898627648831449 , Time: 26.89679789543152\n",
      "Iter 107 Batch_Corr: 0.24209349249285808 , Time: 28.398192167282104\n",
      "Iter 108 Batch_Corr: 0.26209134528687533 , Time: 29.06040382385254\n",
      "Iter 109 Batch_Corr: 0.3560268394381803 , Time: 27.768977642059326\n",
      "Iter 110 Batch_Corr: 0.23368664204948167 , Time: 28.64732527732849\n",
      "Iter 111 Batch_Corr: 0.3037718208245437 , Time: 27.112701654434204\n",
      "Iter 112 Batch_Corr: 0.31816381011707906 , Time: 28.98851704597473\n",
      "Iter 113 Batch_Corr: 0.2477095585582291 , Time: 27.760388612747192\n",
      "Iter 114 Batch_Corr: 0.29330700203506577 , Time: 28.40345287322998\n",
      "Iter 115 Batch_Corr: 0.25777131183691315 , Time: 27.59335470199585\n",
      "Iter 116 Batch_Corr: 0.2374219764940223 , Time: 28.118168592453003\n",
      "Iter 117 Batch_Corr: 0.24145480211951023 , Time: 28.293888568878174\n",
      "Iter 118 Batch_Corr: 0.34900699010842023 , Time: 27.165549516677856\n",
      "Iter 119 Batch_Corr: 0.2573923357314443 , Time: 28.71384024620056\n",
      "Iter 120 Batch_Corr: 0.29343495744009984 , Time: 27.460538148880005\n",
      "Iter 121 Batch_Corr: 0.35879969760261354 , Time: 28.739601612091064\n",
      "Iter 122 Batch_Corr: 0.3614707759913624 , Time: 27.24445152282715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 123 Batch_Corr: 0.3178720566741881 , Time: 28.5900559425354\n",
      "Iter 124 Batch_Corr: 0.18702737573490905 , Time: 27.365731716156006\n",
      "Iter 125 Batch_Corr: 0.2570167250226839 , Time: 28.361891984939575\n",
      "Iter 126 Batch_Corr: 0.2563946692383081 , Time: 27.24531054496765\n",
      "Iter 127 Batch_Corr: 0.3392872092679133 , Time: 27.32044005393982\n",
      "Iter 128 Batch_Corr: 0.15718789947577802 , Time: 28.197855234146118\n",
      "Iter 129 Batch_Corr: 0.23663890186255726 , Time: 27.105314016342163\n",
      "Iter 130 Batch_Corr: 0.3102343447079436 , Time: 29.16761803627014\n",
      "Iter 131 Batch_Corr: 0.12677488268267142 , Time: 27.29450011253357\n",
      "Iter 132 Batch_Corr: 0.2601857584410556 , Time: 27.221988439559937\n",
      "Iter 133 Batch_Corr: 0.25842020791603076 , Time: 28.716936349868774\n",
      "Iter 134 Batch_Corr: 0.20451128346929268 , Time: 26.972769260406494\n",
      "Iter 135 Batch_Corr: 0.3258598219143477 , Time: 28.585195779800415\n",
      "Iter 136 Batch_Corr: 0.18729253691330913 , Time: 27.44684076309204\n"
     ]
    }
   ],
   "source": [
    "#%%capture output --no-stderr\n",
    "\n",
    "test_corr_array = np.empty((batch_no//125, 2))\n",
    "train_corr_array = np.empty((batch_no, 2))\n",
    "\n",
    "save_dir = \"/ssd/joon/2017_11_29_ns/yass/low_pass/\"\n",
    "\n",
    "for i in tnrange(batch_no):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ids = batch_ids[i]\n",
    "    \n",
    "    batch_S = S[ids,:].cuda()\n",
    "    batch_I = I[ids,:].cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    dec_I = model(batch_S.float(), pixel_units)\n",
    "    \n",
    "    loss = loss_fn(batch_I, dec_I)\n",
    "    \n",
    "    #loss_array[i] = loss\n",
    "    \n",
    "    batch_corr = audtorch.pearsonr(batch_I.T, dec_I.T)\n",
    "    mean_batch_corr = torch.mean(batch_corr)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #scheduler.step()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    train_corr_array[i,0] = i\n",
    "    train_corr_array[i,1] = mean_batch_corr.item()\n",
    "    \n",
    "    if i%50 == 49:\n",
    "        \n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"FULL_LP_f10_h40_0.01_w5e6_i\"+str(i)+\"_nn.pt\"))\n",
    "        \n",
    "        test_dec = model(test_S.float().cuda(), pixel_units)\n",
    "        test_batch_corr = audtorch.pearsonr(test_I.T, test_dec.T.cuda())\n",
    "        test_corr = torch.mean(test_batch_corr)\n",
    "        print(\"Test \"+str(i)+\": \"+str(test_corr.item()))\n",
    "        test_corr_array[i//125,1] = test_corr.item()\n",
    "        test_corr_array[i//125,0] = i\n",
    "        \n",
    "    \n",
    "    print(\"Iter \" +str(i)+ \" Batch_Corr: \" + str(mean_batch_corr.item()) + \" , Time: \" +str(duration))\n",
    "    #print(\"Iter \" +str(i)+ \" Batch_MSE: \" + str(loss.item()) + \" , Time: \" +str(duration))\n",
    "    \n",
    "torch.save(model.state_dict(), os.path.join(save_dir, \"FULL_LP_f10_h40_0.01_w5e6_i\"+str(i)+\"_nn.pt\"))\n",
    "\n",
    "np.save(os.path.join(save_dir, \"FULL_LP_f10_h40_0.01_w5e6_train_corr.npy\"), train_corr_array)\n",
    "np.save(os.path.join(save_dir, \"FULL_LP_f10_h40_0.01_w5e6_test_corr.npy\"), test_corr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
